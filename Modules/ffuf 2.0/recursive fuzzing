ğŸ” If This, Then That: Recursive Fuzzing
Situation	Then Do This
You find one or two dirs like /blog/ or /forum/	ğŸ”„ Use -recursion -recursion-depth 1 to auto-dive deeper
You donâ€™t want to scan too deep and waste time	Set a cap: -recursion-depth 1 or 2 max
Youâ€™re seeing nested paths like /users/settings/preferences	Consider bumping depth to 2â€“3 only if prior paths are fruitful
All discovered paths are shallow (e.g. /blog/index.php)	Keep -recursion-depth 1, no need to dig further
You want clean output for reporting	Add -v and -o results.json -of json for structured logging
You know extension site-wide (e.g. PHP)	Use -e .php to double the scan efficiency
Youâ€™re testing locally (HTB, Pwnbox)	Can crank up threads (-t 100+) for speed ğŸ”¥
ğŸ§  Pro Tips
Use --maxtime or --maxtime-job if you need to limit long recursive scans.

Combine with -fc 403 if youâ€™re getting spammed by permission-denied junk.

Use recursion early, but refine it often. Don't just leave it running for hours without reviewing results.

ğŸ§ª Sample Commands to Keep Handy
Basic Recursive Directory Fuzzing:

bash
Copy
Edit
ffuf -w /opt/useful/seclists/Discovery/Web-Content/common.txt:FUZZ -u http://IP/FUZZ -recursion -recursion-depth 1 -v
Recursive + PHP Focus:

bash
Copy
Edit
ffuf -w /opt/useful/seclists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ \
-u http://IP/FUZZ -recursion -recursion-depth 2 -e .php -v
Targeted High-Speed Recon:

bash
Copy
Edit
ffuf -w ./cms-specific.txt:FUZZ -u http://IP/FUZZ -recursion -recursion-depth 1 -e .php -t 100 -v

âœ… Start with -recursion-depth 1
Gets top-level dirs and their immediate children.

Keeps speed decent (~2â€“3x slower than flat scan).

Gives you enough visibility without overwhelming noise or timeouts.

ğŸ” Then Decide If You Wanna Go Deeper:
Once you identify interesting paths like:

/blog/admin/

/dashboard/dev/

/backup/2022/

ğŸ‘‰ You can manually recurse those with a targeted scan, like:

bash
Copy
Edit
ffuf -w /opt/useful/seclists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ \
-u http://target/backup/FUZZ -recursion -recursion-depth 1 -e .php -v
That way you're not going full "scan the Mariana Trench" mode by accident and wasting 20+ minutes.

âŒ Avoid -recursion-depth 5 Off Rip Unlessâ€¦
You're super scoped in (e.g., /staging/ or /test/) and want the full tree.

You're running it overnight and don't care about speed.

You're triaging one directory and need full context.

ğŸ§  TL;DR Flow:
pgsql
Copy
Edit
Run recursion with depth 1 âœ analyze hits âœ recurse interesting ones manually
Keeps it fast, focused, and doesn't murder your box or network. You nailed it, Buck.



ğŸ§ª Example Output (Recursive Depth 1)
Letâ€™s say you run:

bash
Copy
Edit
ffuf -w directory-list-2.3-small.txt:FUZZ -u http://target/FUZZ \
-recursion -recursion-depth 1 -e .php -v
You get these results:

text
Copy
Edit
[Status: 301, Size: 330] | URL | http://target/admin/
[Status: 200, Size: 1200] | URL | http://target/admin/login.php
[Status: 200, Size: 900]  | URL | http://target/admin/settings.php
[Status: 301, Size: 330] | URL | http://target/admin/config/
ğŸ¯ Why This Is Worth Going Deeper
/admin/ returns pages, not just empty 200s or redirects.

You found a nested directory: /admin/config/

That directory wasnâ€™t fuzzed yet â€” you stopped at depth 1.

âœ… Trigger for Depth 2:
Now that /admin/config/ existsâ€¦

Run a targeted depth 1 again on that new directory:

bash
Copy
Edit
ffuf -w directory-list-2.3-small.txt:FUZZ -u http://target/admin/config/FUZZ \
-recursion -recursion-depth 1 -e .php -v
If that returns files like:

text
Copy
Edit
[Status: 200, Size: 1150] | URL | http://target/admin/config/db.php
[Status: 200, Size: 840]  | URL | http://target/admin/config/keys.php
ğŸ’¥ Thatâ€™s depth 2 doing work.

âŒ When Not to Go Deeper:
Letâ€™s say you get:

text
Copy
Edit
[Status: 301, Size: 330] | URL | http://target/css/
[Status: 200, Size: 0]   | URL | http://target/css/main.css
Or:

text
Copy
Edit
[Status: 200, Size: 0]   | URL | http://target/images/
You don't need to recurse:

Static folders (images, css, js, fonts)

Empty folders or ones returning junk

Repeated 403s or 404s

ğŸ§  Rule of Thumb:
If You Seeâ€¦	Do This
index.php, login.php, config/, or any dynamic-looking file	Go deeper
Static stuff (.css, .jpg, /assets/)	Skip
More subdirs in a found directory	Run another depth-1 from that subdir
403s?	Try other wordlists or switch to param fuzzing
So yeah, you're not just watching for hits, you're hunting for:

Nested directories ğŸ”

Dynamic files ğŸ’»

Config or admin stuff ğŸ›‘

Auth or input functionality ğŸ”‘

Once you hit those? Depth 2 is calling.
